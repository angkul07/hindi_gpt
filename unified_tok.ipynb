{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d5aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6d61c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "hinmix_ds = load_dataset(\"kartikagg98/HINMIX_hi-en\", \"lcsalign-hicm\", split=\"train\", streaming=True)\n",
    "hicm_set = hinmix_ds.take(7000)\n",
    "hicm_set = list(hicm_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce9a23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hinmix_sample.txt\", \"w\", encoding=\"utf-8\") as f_txt:\n",
    "    for sample in hicm_set:\n",
    "        f_txt.write(sample[\"text\"] + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9027fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sentences = [sample[\"text\"] for sample in hicm_set]\n",
    "\n",
    "with open(\"hinmix_sample.json\", \"w\", encoding=\"utf-8\") as f_json:\n",
    "    json.dump(sentences, f_json, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9027cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hinmix_dst_e = load_dataset(\"kartikagg98/HINMIX_hi-en\", \"lcsalign-en\", split=\"test\", streaming=True)\n",
    "hinmix_dst_en = hinmix_dst_e.take(2500)\n",
    "hinmix_dst_en = list(hinmix_dst_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c92504a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hinmix_dst_h = load_dataset(\"kartikagg98/HINMIX_hi-en\", \"lcsalign-hi\", split=\"test\", streaming=True)\n",
    "hinmix_dst_hi = hinmix_dst_h.take(2500)\n",
    "hinmix_dst_hi = list(hinmix_dst_hi.take(2500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fcfa7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hinmix_sample.txt\", \"a\", encoding=\"utf-8\") as f_txt:\n",
    "    for sample in hinmix_dst_en:\n",
    "        f_txt.write(sample[\"text\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85b4c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hinmix_sample.txt\", \"a\", encoding=\"utf-8\") as f_txt:\n",
    "    for sample in hinmix_dst_hi:\n",
    "        f_txt.write(sample[\"text\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2333d7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59f6d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/angkul/my_data/coding/agi/hindi_GPT/hinmix_sample.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1de1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.train(\n",
    "    input=file_path,\n",
    "    model_prefix='hinglish_32k',\n",
    "    vocab_size=32000,\n",
    "    model_type='bpe',\n",
    "    user_defined_symbols=['[HI]', '[EN]'],\n",
    "    split_digits=True,\n",
    "    # allow_whitespace_only_pieces=True,\n",
    "    add_dummy_prefix=False,\n",
    "    remove_extra_whitespaces=True,\n",
    "    normalization_rule_name='nfkc',\n",
    "    pad_id=0,\n",
    "    unk_id=1,\n",
    "    bos_id=2,\n",
    "    eos_id=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69c22b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['I', '▁read', '▁पुस्तकालय', '▁में', '▁books']\n",
      "Token IDs: [31954, 2401, 21934, 27, 6911]\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('/home/angkul/my_data/coding/agi/hindi_GPT/hinglish_32k.model')\n",
    "\n",
    "# Tokenize mixed text\n",
    "text = \"I read पुस्तकालय में books\"\n",
    "tokens = sp.encode_as_pieces(text)\n",
    "ids = sp.encode_as_ids(text)\n",
    "\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Token IDs:\", ids)\n",
    "\n",
    "# Output example:\n",
    "# Tokens: ['▁I', '▁read', '▁पुस्त', 'कालय', '▁में', '▁books']\n",
    "# Token IDs: [10, 42, 1500, 1501, 2500, 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01ea3997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31954, 2401, 21934, 27, 6911]\n",
      "I read पुस्तकालय में books\n"
     ]
    }
   ],
   "source": [
    "sen = sp.Encode(text)\n",
    "print(sen)\n",
    "print(sp.Decode(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "240c17d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.GetPieceSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85e4aa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Story_no', 'Sentence', 'Discourse Mode'],\n",
      "        num_rows: 9968\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "hindi_discourse = load_dataset('/home/angkul/my_data/coding/agi/hindi_GPT/hindi_discourse.py')\n",
    "print(hindi_discourse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "364f8988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hindi_discourse = hindi_discourse['train'][:5000]['Sentence']\n",
    "hindi_discourse_subset = Dataset.from_dict((hindi_discourse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a205a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tinystories = load_dataset('roneneldan/TinyStories', streaming=True)['train']\n",
    "tinystories_subset = Dataset.from_list(list(tinystories.take(10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35c24560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['train'],\n",
      "    num_rows: 9968\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(type(tinystories_subset))\n",
    "print(type(hindi_discourse_subset))\n",
    "print((tinystories_subset))\n",
    "print((hindi_discourse_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "addf90d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Discourse Mode': 1,\n",
       " 'Sentence': 'चेहरे पर इस की आँखें बहुत अजीब थीं।',\n",
       " 'Story_no': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_discourse_subset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07e7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hindi_discourse_subset = hindi_discourse_subset.take(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13ef87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tinystories_texts = tinystories_subset['text']\n",
    "hindi_sentences = [item['Sentence'] for item in hindi_discourse_subset['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2f5dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_texts = [\n",
    "#     {'text': text, 'Sentence': sentence}\n",
    "#     for text, sentence in zip(tinystories_texts, hindi_sentences)\n",
    "# ]\n",
    "\n",
    "combined_texts = tinystories_texts + hindi_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "395f43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset = Dataset.from_dict({'text': combined_texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5ad04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19968"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef1725b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeed99ec81b44a4d898a9737377bf3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/19968 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the dataset to disk\n",
    "combined_dataset.save_to_disk('combined_dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66cded22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Johnny and his mom were in the park. Johnny skipped around the pathways, scanning for interesting things. He discovered a tiny bug, just a few centimeters long. He was very excited and picked it up carefully. As he watched it, the bug began to shrink! Johnny was amazed and asked his mom to explain. \\n\\n\"The bug isn\\'t really shrinking, Johnny,\" his mom said. \"It\\'s playing a trick on you. That\\'s called camouflaging. It\\'s shrinking its body to look like other things around it and protect itself.\" \\n\\n\"It\\'s kind of like when I have to hide behind the couch,\" Johnny said. \\n\\nHis mom laughed. \"Exactly,\" she replied. \"Animals are so clever. You have to be careful around them. We have to show them value and respect.\" \\n\\nJohnny looked at the bug intently. He was full of admiration and respect. \"Okay,\" he said. \"I promise to be careful.\"'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset['text'][5002]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
