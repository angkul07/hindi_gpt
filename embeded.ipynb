{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from bpe import HindiTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/angkul/my_data/coding/agi/hindi_gpt/hindi.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = HindiTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hindiDataset:\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i: i+max_length]\n",
    "            target_chunk = token_ids[i+1: i+max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids[index], self.target_ids[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(txt, batch_size, max_length, stride, shuffle=True, drop_last = True, num_workers=0):\n",
    "\n",
    "    dataset = hindiDataset(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size, shuffle, drop_last=drop_last, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 678, 6884,  109, 5216]]), tensor([[6884,  109, 5216, 6884]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader(\n",
    "    raw_text, batch_size=1, max_length=4, stride=2, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  tensor([[ 109, 5216, 6884, 2367]])\n",
      "Target:  tensor([[5216, 6884, 2367, 4942]])\n"
     ]
    }
   ],
   "source": [
    "inputs1, targets1 = next(data_iter)\n",
    "print(\"Input: \", inputs1)\n",
    "print(\"Target: \", targets1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 110126\n",
    "output_dim = 256\n",
    "context_length = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  tensor([[   678,   6884,    109,   5216],\n",
      "        [  6884,   2367,   4942,    103],\n",
      "        [  6787,  35922,    721,    114],\n",
      "        [   177,   1070,    137, 107782],\n",
      "        [  1494,    114,  12652,    108],\n",
      "        [  1085,    103,    594,  10173],\n",
      "        [   110,    251,  17785,   8264],\n",
      "        [   103,    494,    110,   9219]])\n",
      "Target:  tensor([[  6884,    109,   5216,   6884],\n",
      "        [  2367,   4942,    103,   6787],\n",
      "        [ 35922,    721,    114,    177],\n",
      "        [  1070,    137, 107782,   1494],\n",
      "        [   114,  12652,    108,   1085],\n",
      "        [   103,    594,  10173,    110],\n",
      "        [   251,  17785,   8264,    103],\n",
      "        [   494,    110,   9219,    108]])\n",
      "Input shape:  torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader(\n",
    "    raw_text, batch_size=8, max_length=4, stride=4, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Input: \", inputs)\n",
    "print(\"Target: \", targets)\n",
    "print(\"Input shape: \", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.1929,  1.0425, -1.2517,  ...,  0.7110, -0.0654, -1.7875],\n",
      "         [ 0.5091,  0.7915,  0.9778,  ..., -1.0899,  0.6510,  0.5326],\n",
      "         [-0.4585,  1.2861, -0.3517,  ...,  0.0103,  0.4264,  0.6903],\n",
      "         [ 1.2590, -0.9492, -0.6068,  ...,  0.1470,  0.2408, -1.0546]],\n",
      "\n",
      "        [[ 0.5091,  0.7915,  0.9778,  ..., -1.0899,  0.6510,  0.5326],\n",
      "         [ 0.3681, -1.2437, -0.7266,  ..., -0.2342, -0.3608,  0.7382],\n",
      "         [ 1.2890,  1.1843, -0.0129,  ..., -0.9807, -2.2260, -0.9126],\n",
      "         [-0.5270,  0.4361,  0.2539,  ...,  0.5521,  0.4655, -1.9145]],\n",
      "\n",
      "        [[-0.7450, -1.1314,  1.0025,  ...,  0.4701, -0.4298,  0.6751],\n",
      "         [-0.0891,  0.8334,  0.0422,  ..., -0.4854, -1.4634, -1.1526],\n",
      "         [-0.0821, -0.3032,  0.6417,  ..., -0.1867, -0.0181,  0.2435],\n",
      "         [ 0.8728,  0.6619,  0.3223,  ...,  1.1945,  0.3440,  0.1549]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8437, -1.0063, -0.8142,  ...,  0.2404, -1.3223, -1.8691],\n",
      "         [-0.5270,  0.4361,  0.2539,  ...,  0.5521,  0.4655, -1.9145],\n",
      "         [-0.6819, -0.3234, -0.1907,  ..., -0.4319, -0.2607,  2.1813],\n",
      "         [ 0.8235, -0.0367, -0.1210,  ..., -0.1904,  0.6793, -1.4613]],\n",
      "\n",
      "        [[-0.6234,  0.1538,  0.3519,  ...,  0.8983,  0.0822, -0.3530],\n",
      "         [ 0.6826,  0.5391, -0.2530,  ..., -1.9160, -0.8593,  0.2946],\n",
      "         [-1.3051,  0.9575,  0.6454,  ..., -0.8007, -0.4101,  1.0795],\n",
      "         [-0.9554,  1.1062, -1.5119,  ...,  0.9788, -1.2595,  0.9232]],\n",
      "\n",
      "        [[-0.5270,  0.4361,  0.2539,  ...,  0.5521,  0.4655, -1.9145],\n",
      "         [ 1.1907, -0.5068,  1.5839,  ..., -0.7204,  1.9190, -2.2160],\n",
      "         [-0.6234,  0.1538,  0.3519,  ...,  0.8983,  0.0822, -0.3530],\n",
      "         [ 0.6319,  2.6952,  0.5200,  ..., -1.6589, -0.5722,  1.5101]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(token_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
